# Cache Coverage Examples

## Question Flow with Caching

### âœ… Questions That Get Cached

#### 1. **Greetings** (NO LLM CALL - Instant)
```
"hi" â†’ is_greeting() = TRUE â†’ return greeting (instant, <1ms)
"hello" â†’ is_greeting() = TRUE â†’ return greeting (instant)
"hey" â†’ is_greeting() = TRUE â†’ return greeting (instant)
"how are you" â†’ is_greeting() = TRUE â†’ return greeting (instant)
"thanks" â†’ is_greeting() = TRUE â†’ return greeting (instant)
```
**Cache: No (Special handler, not LLM)** âš¡

---

#### 2. **Schema Questions** (NO LLM CALL - Instant)
```
"show me table columns" â†’ schema detection â†’ get_database_schema() (cached)
"what are the columns?" â†’ schema detection â†’ REUSE CACHED SCHEMA (instant)
"show tables" â†’ schema detection â†’ REUSE CACHED SCHEMA (instant)
"list columns" â†’ schema detection â†’ REUSE CACHED SCHEMA (instant)
```
**Cache: Database schema cached (3600 sec TTL)** âš¡

---

#### 3. **Data Analysis Questions** (LLM + Response Cache)

**First time asking:**
```
Q: "show total subscribers"
   â†“
normalize: "total subscribers"
   â†“
LLM call: "Analyze database, find total subscribers"
   â†“
Query: SELECT COUNT(*) FROM giza_data
   â†“
LLM generates answer: "We have 4,858 subscribers..."
   â†“
Cache saved with key: MD5(system_prompt + "total subscribers")
   â†“
Return: {"answer": "...", "cached": False, "time": 8.2s}
```

**Second time asking (same question):**
```
Q: "show total subscribers"
   â†“
normalize: "total subscribers"
   â†“
Cache lookup: MD5(system_prompt + "total subscribers") â†’ HIT!
   â†“
Return: {"answer": "...", "cached": True, "time": <1ms}
```

**Asking similar question (normalized):**
```
Q: "show me total subscribers" OR "what about total subscribers?"
   â†“
normalize: "total subscribers"  (same as before!)
   â†“
Cache lookup: MD5(...) â†’ HIT!
   â†“
Return cached answer instantly!
```

---

## Cache Coverage Matrix

| Question | Handler | Cache Type | Speed |
|---|---|---|---|
| "Hi" | Greeting | N/A | âš¡ <1ms |
| "Hello" | Greeting | N/A | âš¡ <1ms |
| "How are you?" | Greeting | N/A | âš¡ <1ms |
| "Show columns" | Schema | DB Schema | âš¡ <1ms |
| "What are the tables?" | Schema | DB Schema | âš¡ <1ms |
| "Total subscribers" | LLM | Response | ðŸ”´ ~8s 1st, âš¡ <1ms 2nd |
| "Show total subscribers" | LLM | Response | ðŸ”´ ~8s 1st, âš¡ <1ms 2nd |
| "Subscribers count" | LLM | Response | ðŸ”´ ~8s 1st, âš¡ <1ms 2nd |
| "ARPU by technology" | LLM | Response | ðŸ”´ ~8s 1st, âš¡ <1ms 2nd |
| "tell me ARPU analysis" | LLM | Response | ðŸ”´ ~8s 1st, âš¡ <1ms 2nd |
| "churn risk" | LLM | Response | ðŸ”´ ~8s 1st, âš¡ <1ms 2nd |
| "churn analysis" | LLM | Response | ðŸ”´ ~8s 1st, âš¡ <1ms 2nd |

---

## Normalization Examples

**These all map to the same cache entry:**
```
Original Question              Normalized              Cache Entry
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"show total subscribers"  â†’  "total subscribers"  âœ… SAME
"can you show total subs" â†’  "total subscribers"  âœ… SAME
"Tell me total subscribers" â†’ "total subscribers" âœ… SAME
"What's the total subscribers" â†’ "total subscribers" âœ… SAME

"ARPU by technology"       â†’  "arpu by technology"  âœ… SAME
"show ARPU by technology?" â†’  "arpu by technology"  âœ… SAME
"Can you ARPU by technology" â†’ "arpu by technology" âœ… SAME
"Tell me ARPU by tech"    â†’  "arpu by technology"  âœ… SAME
```

---

## Performance Timeline Example

```
Timeline of User Interactions
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

09:00:00  Q1: "show total subscribers"
          â””â”€ ðŸ”´ 8.2s (LLM processing + DB query)
          â””â”€ ðŸ’¾ Response cached

09:00:15  Q2: "hello"
          â””â”€ âš¡ <1ms (Greeting detected, no LLM)

09:00:30  Q3: "show total subscribers"  (exact repeat)
          â””â”€ âš¡ <1ms (ðŸ’¾ Cache HIT)

09:00:45  Q4: "what about total subscribers?"
          â””â”€ âš¡ <1ms (normalized â†’ same as Q1, ðŸ’¾ Cache HIT)

09:01:00  Q5: "show table columns"
          â””â”€ âš¡ <1ms (Schema cached)

09:01:15  Q6: "ARPU by technology"
          â””â”€ ðŸ”´ 7.8s (New question, LLM processes)
          â””â”€ ðŸ’¾ Response cached

09:01:30  Q7: "tell me ARPU analysis"
          â””â”€ âš¡ <1ms (Normalized â†’ "arpu analysis", ðŸ’¾ Cache HIT)

Total time saved by caching: ~25 seconds
```

---

## How to Check Cache Status

**In the response, look for:**

```
ðŸ“Š **Metrics:**
  â€¢ ðŸ’¾ **Cached Response** (instant)  â† YES = Cached
  â€¢ Tokens: 150 input + 320 output = 470 total
  â€¢ Time: 8.2s                        â† Visible only if NOT cached
```

**If you see:**
- ðŸ’¾ **Cached Response** â†’ Answer came from cache (instant)
- No cache indicator + Time shown â†’ Fresh LLM call

---

## Summary

âœ… **Questions that DON'T call LLM (instant):**
- Greetings: "hi", "hello", "thanks", etc.
- Schema: "show columns", "what tables", etc.

âœ… **Questions WITH response caching:**
- First ask: ~8-10 seconds (LLM thinks)
- Repeat ask: <1ms (instant, from cache)
- Similar phrasing: <1ms (normalized match, from cache)

âœ… **Cache validations:**
- Shows ðŸ’¾ indicator when cached
- Shows execution time when NOT cached
- Cache expires after 1 hour (TTL)
- Stores up to 50 different questions
